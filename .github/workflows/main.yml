name: Convert HF Model to GGUF

on:
  workflow_dispatch:
    inputs:
      repo_id:
        description: 'HuggingFace repo ID (e.g., meta-llama/Llama-2-7b-hf)'
        required: true
      revision:
        description: 'Optional revision (e.g., main or commit hash)'
        required: false

jobs:
  convert:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout your repo
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        pip install torch transformers sentencepiece huggingface_hub

    - name: Download model from Hugging Face
      run: |
        mkdir -p hf-model
        if [ -z "${{ github.event.inputs.revision }}" ]; then
          python3 -c "from huggingface_hub import snapshot_download; snapshot_download(repo_id='${{ github.event.inputs.repo_id }}', local_dir='hf-model')"
        else
          python3 -c "from huggingface_hub import snapshot_download; snapshot_download(repo_id='${{ github.event.inputs.repo_id }}', revision='${{ github.event.inputs.revision }}', local_dir='hf-model')"
        fi

    - name: Clone llama.cpp
      run: |
        git clone https://github.com/ggml-org/llama.cpp.git
        cd llama.cpp
        pip install -r requirements.txt

    - name: Convert to GGUF
      run: |
        mkdir -p converted
        cd llama.cpp
        python3 convert-hf-to-gguf.py ../hf-model --outfile ../converted/model.gguf

    - name: Upload GGUF model
      uses: actions/upload-artifact@v4
      with:
        name: gguf-model
        path: converted/model.gguf
